{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXxeYA_z_J4t"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4j4Bj3mO8vQ",
        "outputId": "f3f231ea-2104-4456-95d6-e6f4db86fc06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensorflow/Keras: 2.12.0\n",
            "pandas: 1.5.3\n",
            "numpy: 1.22.4\n",
            "sklearn: 1.2.2\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "from tensorflow import keras # for building Neural Networks\n",
        "print('Tensorflow/Keras: %s' % keras.__version__) # print version\n",
        "from keras.models import Sequential # for creating a linear stack of layers for our Neural Network\n",
        "from keras import Input # for instantiating a keras tensor\n",
        "from keras.layers import Dense, SimpleRNN # for creating regular densely-connected NN layers and RNN layers\n",
        "from keras.layers import Embedding, Dense, LSTM, Dropout\n",
        "\n",
        "# Data manipulation\n",
        "import pandas as pd # for data manipulation\n",
        "print('pandas: %s' % pd.__version__) # print version\n",
        "import numpy as np # for data manipulation\n",
        "print('numpy: %s' % np.__version__) # print version\n",
        "import math # to help with data reshaping of the data\n",
        "\n",
        "# Sklearn\n",
        "import sklearn # for model evaluation\n",
        "print('sklearn: %s' % sklearn.__version__) # print version\n",
        "from sklearn.model_selection import train_test_split # for splitting the data into train and test samples\n",
        "from sklearn.metrics import mean_squared_error # for model evaluation metrics\n",
        "from sklearn.preprocessing import MinMaxScaler # for feature scaling\n",
        "# prepare data for lstm\n",
        "from pandas import read_csv\n",
        "from pandas import DataFrame\n",
        "from pandas import concat\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import MinMaxScaler\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pg9D9hDg2RI5",
        "outputId": "4ad07c55-d73a-48fe-8e46-c9a0d36a0549"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n",
            "/gdrive/MyDrive/_RESEARCH/UPM/RV Jesus\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive', force_remount=True)\n",
        "%cd \"/gdrive/MyDrive/_RESEARCH/UPM/RV Jesus\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgnCCGFuSC-U"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TpbX_gNXO8vS"
      },
      "outputs": [],
      "source": [
        "def concatenate_outputs_of_generation(generator):\n",
        "  c = 0\n",
        "  a =None\n",
        "  for i in generator:\n",
        "    if c == 0:\n",
        "      a = i[1]\n",
        "      c=1\n",
        "    else:\n",
        "      a = np.concatenate((a,i[1]))\n",
        "  return a\n",
        "\n",
        "def average(lst):\n",
        "    return sum(lst) / len(lst)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B8rV7z_24u3T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54063c0a-8157-4761-92d4-9c330b9e72df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyquaternion\n",
            "  Downloading pyquaternion-0.9.9-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pyquaternion) (1.22.4)\n",
            "Installing collected packages: pyquaternion\n",
            "Successfully installed pyquaternion-0.9.9\n"
          ]
        }
      ],
      "source": [
        "%pip install pyquaternion\n",
        "from pyquaternion import Quaternion\n",
        "\n",
        "SCALE_FACTOR_SCENES = 1.2\n",
        "\n",
        "def calculate_MDE(y,y_predicted):\n",
        "  accumulator = 0\n",
        "\n",
        "  for i in range(y.shape[0]):\n",
        "    distance = np.linalg.norm((np.array([y[i,0]-y_predicted[i,0],y[i,1]-y_predicted[i,1]], dtype = \"float32\")),axis=0)\n",
        "    accumulator += distance\n",
        "\n",
        "  return (accumulator/y.shape[0])/SCALE_FACTOR_SCENES\n",
        "\n",
        "def calculate_MDE_quaternion(df,y,y_predicted):\n",
        "  accumulator = 0\n",
        "\n",
        "  for i in range(y.shape[0]):\n",
        "    y_real = Quaternion(df.iloc[i,:4]).rotate([y[i,0],y[i,1],y[i,2]])\n",
        "    y_pred = Quaternion(df.iloc[i,:4]).rotate([y_predicted[i,0],y_predicted[i,1],y_predicted[i,2]])\n",
        "\n",
        "    distance = np.linalg.norm((np.array([y_real[0]-y_pred[0],y_real[2]-y_pred[2]], dtype = \"float32\")),axis=0)\n",
        "    accumulator += distance\n",
        "\n",
        "  return (accumulator/y.shape[0])/SCALE_FACTOR_SCENES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vrJqcxyVO8vR"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model,list_generators, scale=False):\n",
        "  res=[]\n",
        "  print('---------- Evaluation on Test Data ----------')\n",
        "  for a in range(0,len(list_generators)):\n",
        "      gener=list_generators[a]\n",
        "      scaler= gener[3]\n",
        "\n",
        "      test_generator=gener[1]\n",
        "      pred_test = model.predict_generator(test_generator)\n",
        "      y_test =  concatenate_outputs_of_generation(test_generator)\n",
        "\n",
        "      ## Data transform\n",
        "      pred_test_scaled= pred_test\n",
        "      y_test_scaled= y_test\n",
        "\n",
        "      if scale:\n",
        "        pred_test_scaled= scaler.inverse_transform(pred_test)\n",
        "        y_test_scaled= scaler.inverse_transform(y_test)\n",
        "\n",
        "      if model == 'QUAT_3LABEL':\n",
        "        #print('MDE QUAT: ' + str(calculate_MDE_quaternion(y_test_scaled, pred_test_scaled)), end = \"||||\")\n",
        "        res.append( calculate_MDE_quaternion(y_test_scaled, pred_test_scaled))\n",
        "      else:\n",
        "        #print('MDE: ' + str(calculate_MDE(y_test_scaled, pred_test_scaled)), end = \"||||\")\n",
        "        res.append( calculate_MDE(y_test_scaled, pred_test_scaled))\n",
        "\n",
        "  print(\"\")\n",
        "  return res\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dHsOIgoRolEb"
      },
      "outputs": [],
      "source": [
        "import keras.backend as K\n",
        "\n",
        "def squared_euclidean_distance(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Euclidean distance loss\n",
        "    https://en.wikipedia.org/wiki/Euclidean_distance\n",
        "    :param y_true: TensorFlow/Theano tensor\n",
        "    :param y_pred: TensorFlow/Theano tensor of the same shape as y_true\n",
        "    :return: float\n",
        "    \"\"\"\n",
        "    return K.sum(K.square(y_pred - y_true), axis=-1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQdz0CX7WjXj",
        "outputId": "63bb996b-26cb-4404-ed72-7763378356ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>>>>>>>>>>>>>>>BASELINE_ORG_sr_short<<<<<<<<<<<<<<<<\n",
            "---------- Evaluation on Test Data ----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-aabaf81fc6b9>:9: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  pred_test = model.predict_generator(test_generator)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            ">>>>>>>>>> TOTAL MDE: BASELINE_ORG_sr_short: 0.01460729804657237\n",
            "\n",
            ">>>>>>>>>>>>>>>>QUAT_sr_short<<<<<<<<<<<<<<<<\n",
            "---------- Evaluation on Test Data ----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-aabaf81fc6b9>:9: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  pred_test = model.predict_generator(test_generator)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            ">>>>>>>>>> TOTAL MDE: QUAT_sr_short: 0.009924062431574466\n",
            "\n",
            ">>>>>>>>>>>>>>>>BASELINE_ORG_mf_short<<<<<<<<<<<<<<<<\n",
            "---------- Evaluation on Test Data ----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-aabaf81fc6b9>:9: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  pred_test = model.predict_generator(test_generator)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            ">>>>>>>>>> TOTAL MDE: BASELINE_ORG_mf_short: 0.015624802817037993\n",
            "\n",
            ">>>>>>>>>>>>>>>>QUAT_mf_short<<<<<<<<<<<<<<<<\n",
            "---------- Evaluation on Test Data ----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-aabaf81fc6b9>:9: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  pred_test = model.predict_generator(test_generator)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            ">>>>>>>>>> TOTAL MDE: QUAT_mf_short: 0.010577582326507365\n",
            "\n",
            ">>>>>>>>>>>>>>>>BASELINE_ORG_sl_short<<<<<<<<<<<<<<<<\n",
            "---------- Evaluation on Test Data ----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-aabaf81fc6b9>:9: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  pred_test = model.predict_generator(test_generator)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            ">>>>>>>>>> TOTAL MDE: BASELINE_ORG_sl_short: 0.028522984281108655\n",
            "\n",
            ">>>>>>>>>>>>>>>>QUAT_sl_short<<<<<<<<<<<<<<<<\n",
            "---------- Evaluation on Test Data ----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-aabaf81fc6b9>:9: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  pred_test = model.predict_generator(test_generator)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            ">>>>>>>>>> TOTAL MDE: QUAT_sl_short: 0.02212953670573277\n",
            "\n",
            ">>>>>>>>>>>>>>>>BASELINE_ORG_all_short<<<<<<<<<<<<<<<<\n",
            "---------- Evaluation on Test Data ----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-aabaf81fc6b9>:9: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  pred_test = model.predict_generator(test_generator)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            ">>>>>>>>>> TOTAL MDE: BASELINE_ORG_all_short: 0.01874395863813001\n",
            "\n",
            ">>>>>>>>>>>>>>>>QUAT_all_short<<<<<<<<<<<<<<<<\n",
            "---------- Evaluation on Test Data ----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-aabaf81fc6b9>:9: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  pred_test = model.predict_generator(test_generator)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            ">>>>>>>>>> TOTAL MDE: QUAT_all_short: 0.014028455753364316\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "subfolders = ['BASELINE_ORG','QUAT']#,'BASELINE_CIRC','BASE_PLUS']\n",
        "models = [('sr_short','dfSRshort.pkl'),('mf_short','dfMFshort.pkl'),('sl_short','dfSLshort.pkl'),('all_short','Allshort.pkl')]\n",
        "#models = [('sr_long','dfSRlong.pkl'),('mf_long','dfMFlong.pkl'),('sl_long','dfSLlong.pkl'),('all_long','Alllong.pkl')]\n",
        "\n",
        "for model_name, df_name in models:\n",
        "  for folder in subfolders:\n",
        "    if os.path.isfile('outputPickles/' + folder + '/models/'+model_name+'.h5'):\n",
        "      ## Cargamos el modelo\n",
        "      mymodel = keras.models.load_model('outputPickles/' + folder + '/models/'+model_name+'.h5', custom_objects={'squared_euclidean_distance':squared_euclidean_distance})\n",
        "\n",
        "      ## Cargamos los generators\n",
        "      list_generators = \"\"\n",
        "      import pickle\n",
        "      with open(\"outputPickles/\" + folder + \"/\"+ df_name, \"rb\") as infile:\n",
        "        list_generators = pickle.load(infile)\n",
        "\n",
        "      print(\">>>>>>>>>>>>>>>>\" + folder + \"_\" + model_name +\"<<<<<<<<<<<<<<<<\")\n",
        "      res = evaluate_model(mymodel, list_generators)#, list_scalers)\n",
        "      print(\">>>>>>>>>> TOTAL MDE: \" + folder + \"_\" + model_name +\": \"+ str(average(res)), end = \"\\n\\n\")\n",
        "    else:\n",
        "      print('outputPickles/' + folder + '/models/'+model_name+\".h5---> No existe\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuClass": "premium"
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}